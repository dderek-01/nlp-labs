{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction to Python (Part 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the third part of the Introduction to Python for Natural Language Engineering module.  \n",
    "These notebooks are designed to give you the working knowledge of Python necessary to complete the lab sessions for Natural Language Engineering. \n",
    "\n",
    "From the first 2 notebooks you should be familiar with a range of data types including strings, lists, sets, tuples and dictionaries.  You should also be familiar with defining your own functions as well as a number of built-in functions including print(), type(), range() and zip().  This notebook will introduce a number of more complex features including classes, list comprehensions, map(), lazy generators and running python programs in other environments.  It will also introduce a useful Python library for data analysis - Pandas.\n",
    "\n",
    "Some extension material could be left until later in the term if you do not have time to tackle it now.\n",
    "\n",
    "As in the last session:-\n",
    "\n",
    "- Run all of the code cells as you work through the notebook. \n",
    "- Try to understand what is happening in each code cell and predict the output before running it.\n",
    "- Complete all of the exercises.\n",
    "- Discuss answers and ask questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyone who has previously programmed in Java will be familiar with the concept of objects.  A Python class  is a complex type whichallows the encapsulation of attributes and methods.  You have already been using a number of Python classes (e.g., strings, lists, dictionaries).  However, sometimes it is useful to be able to define new classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    passmark=50  #this is a class variable which will be shared by all instances of Student\n",
    "    \n",
    "    def __init__(self,name,mark):  \n",
    "        \"\"\"\n",
    "        initialisation method run when a new instance is created\n",
    "        in general it can take any number of arguments (in addition to self)\n",
    "        :param self: this instance, name: name of Student, mark: mark of Student\n",
    "        \"\"\"\n",
    "        self.name=name  #store the name in an instance variable called name\n",
    "        self.mark=mark  #store the mark in an instance variable called mark\n",
    "        \n",
    "    def passes(self):\n",
    "        \"\"\"\n",
    "        has this student passed the course?\n",
    "        check whether the mark associated with this instance is greater than the class variable Passmark\n",
    "        :param self: this instance\n",
    "        :returns boolean\n",
    "        \"\"\"\n",
    "        return self.mark > Student.passmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an instance of a class (remember every class defines a type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student1 = Student(\"Jack\",40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(student1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student1.passes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1a\n",
    "Create a new student whose name is \"Jill\" and whose mark is 60.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1b\n",
    "Write some code which takes a list of Student objects and returns a list of the names of students who failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The map function\n",
    "This takes a function and an iterable (e.g. a list) as arguments. It then applies the function to every item of the iterable, returning a list of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we make a function, which we will pass to the map function in the next cell\n",
    "natural_numbers = range(5)\n",
    "def square(n):\n",
    "    return n**2\n",
    "\n",
    "square(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_numbers = map(square, natural_numbers)\n",
    "for i in squared_numbers:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate(char):\n",
    "     return \"*\" + char + \"*\"\n",
    "\n",
    "decorate(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decorated_characters = map(decorate, \"Hello\")\n",
    "type(decorated_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decorated_characters = map(decorate, \"Hello\")\n",
    "for char in (decorated_characters):\n",
    "     print (char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2a\n",
    "In the blank cell below write a function called `add_exclamation` which adds a `'!'` to the input string. Then map add_exclamation to print each word in `opening_line`, followed by an exclamation point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_line=\"It was the best of times, it was the worst of times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b\n",
    "In the next code cell we see code that determines the kinds of tokens found in a list. A token is a specific occurrence of a basic unit of lexical processing, typically a word or an item of punctuation.\n",
    "\n",
    "- Study the programme, in particular the string methods. These are very useful in NLP.\n",
    "- Experiment with the string methods using the empty cell until you understand how they work in special cases such as a single space and a single punctuation mark.\n",
    "- The programme will only assign one feature to each token. Are there any cases where more than one feature should be assigned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(input_text):\n",
    "    \"\"\"\n",
    "    Take an input text, split it into tokens, find the\n",
    "    token's shape, make a feature\n",
    "    vector with the token itself and its shape, return\n",
    "    a list of all token feature vectors found in the input.\n",
    "    :param input_text: A character string containing spaces\n",
    "    :return: A list of token feature vectors (token, shape).\n",
    "        Sample output: [('a', 'alpha'), ('7', 'digit'), ('A27', 'alnum')]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Here we define a token as being delimited by a whitespace:\n",
    "    \n",
    "    tokens = input_text.split()\n",
    "    return map(make_token_feature_vector, tokens)\n",
    "\n",
    "\n",
    "def make_token_feature_vector(token):\n",
    "    \"\"\"\n",
    "    Given a token, extract its shape and return a\n",
    "    vector with the token itself and its shape\n",
    "    :param token: A character string\n",
    "    :return: A tuple (token, shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    if token.isalpha():\n",
    "        return (token, \"alpha\")\n",
    "    elif token.isdigit():\n",
    "        return (token, \"digit\")\n",
    "    elif token.isalnum():\n",
    "        return (token, \"alnum\")\n",
    "    elif token in \",:;\":  \n",
    "        return (token, \"punctuation\")\n",
    "    elif token in \".!?\":  \n",
    "        return (token, \"sentence_end\")\n",
    "    elif token == \"\\n\":  \n",
    "        return (token, \"paragraph_end\")\n",
    "    else:\n",
    "        return (token, \"other\")\n",
    "\n",
    "input_file_path=\"sample_text.txt\"\n",
    "with open(input_file_path) as input_file:\n",
    "    sample_text=input_file.read()\n",
    "for token in make_tokens(sample_text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension\n",
    "\n",
    "List comprehensions are a *pythonic* way of reducing the number of lines of code in your programs - they are equivalent to a `for ... in` loop.  \n",
    "\n",
    "If we want to create a list of the first 4 square numbers, we could use the following 3 lines:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares=[]\n",
    "for x in range(4):\n",
    "    squares.append(x**2)\n",
    "squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use the following list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares=[x**2 for x in range (4)]\n",
    "squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions can be used to create a list of decorated characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"*\" + char + \"*\" for char in \"Hello\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function, `is_even` returns `True` for even numbers, and `False`, otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember the mod operator % returns the residue after integer division\n",
    "def is_even(n):\n",
    "    return not n % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_even(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_even(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions can be used with our `is_even` function to create a list of squares for the first even numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[square(n) for n in range(15) if is_even(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3a\n",
    "In the blank cell below create a list of the odd numbers in the range 0-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3b\n",
    "In the blank cell below create a list of numbers in the range 0-20 that are both odd AND divisible by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas dataframes\n",
    "We will be using tables in various ways later in the module. We now look at how to store tables as Pandas dataframes. \n",
    "\n",
    "If you want more details, a good starting point is [10 Minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html).\n",
    "\n",
    "First, let's create some data to put in the table. This is meant to be the results of some experiment that we have underaken. \n",
    "\n",
    "To do this we create a list of tuples, where each tuple is a row in the table.\n",
    "- We use `display` rather than `print` as it produces a nicer looking table.\n",
    "\n",
    "Run the cell and make sure you understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = [\n",
    "    (10,0.674),\n",
    "    (20,0.708),\n",
    "    (30,0.721),\n",
    "    (40,0.744),\n",
    "    (50,0.748),\n",
    "    (60,0.759),\n",
    "    (70,0.762),\n",
    "    (80,0.769),\n",
    "    (90,0.773),\n",
    "    (100,0.775)]\n",
    "df = pd.DataFrame(results,columns = [\"Sample Size\",\"Accuracy\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a table from columns\n",
    "We now create the same dataframe, but in a different way. This time we specify the contents by giving a list for each column.\n",
    "- The column lists and `zip`'d together to create the same list of tuples we saw above, one tuple for each row of the table.\n",
    "- `zip` returns an iterator of tuples, so  `list` is needed to give the required list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = list(range(10,110,10))\n",
    "scores = [0.674,0.708,0.721,0.744,0.748,0.759,0.762,0.769,0.773,0.775]\n",
    "df = pd.DataFrame(list(zip(sample_sizes,scores)),columns = [\"Sample Size\",\"Score\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data in a dataframe\n",
    "In the following cell we see how to plot the dataframe containing our pretend experimental results.\n",
    "- Note that some of the settings are determined by code in the first cell of the notebook.\n",
    "- `x=0` indicates that the first column of the data provides the values on the x-axis.\n",
    "- See [pandas.DataFrame.plot](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, however, we need this bit of jupyter notebook 'magic code' (which isn't python and is identified by the `%` at the start of the line), to make sure that graphs and plots are produced in the notebook as output rather than in a separate window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot(kind=\"bar\",x=0,legend=False,title=\"Experimental Results\",yticks=(0.6,0.65,0.7,0.75,0.8))\n",
    "# set the x-axis label\n",
    "ax.set_xlabel(\"Sample Size\")\n",
    "# set the y-axis label\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "# set the y axis range \n",
    "ax.set_ylim(0.6,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have results for two competing methods. \n",
    "\n",
    "We will have a three rather than two columns in our dataframe:\n",
    "- the first column holds the sample size\n",
    "- the second column holds one set of results\n",
    "- the third column holds a second set of results\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_sizes = list(range(10,110,10))\n",
    "your_results = [0.674,0.708,0.721,0.744,0.748,0.759,0.762,0.769,0.773,0.775]\n",
    "my_results = [0.774,0.788,0.801,0.844,0.852,0.855,0.860,0.862,0.863,0.864]\n",
    "\n",
    "df = pd.DataFrame(list(zip(sample_sizes,your_results,my_results)),columns = [\"Sample Size\",\"Your Score\",\"My Score\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show how to visualise these results.\n",
    "- This time we want a legend.\n",
    "- We also need to expand the limits being shown on the y-axis\n",
    "\n",
    "Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot(kind=\"bar\",x=0,title=\"Experimental Results\",yticks=(0.6,0.65,0.7,0.75,0.8))\n",
    "# set the x-axis label\n",
    "ax.set_xlabel(\"Sample Size\")\n",
    "# set the y-axis label\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "# set the y axis range \n",
    "ax.set_ylim(0.6,0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 4\n",
    "Can you generate a scatter plot of your results against my results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy generators (extension material)\n",
    "We now introduce lazy generators, an important form of function in python. A lazy generator does not calculate its results all at once, but returns them one a a time for iteration. The `enumerate` function which we saw earlier is a lazy generator.\n",
    "\n",
    "You can define lazy generator functions by using `yield` instead of `return`. When the function reaches a `yield` command it yields the argument and suspends execution without terminating and returns control to the level that called the function. The next time it is called it it resumes from the same place that it was left. There is no requirement to have a single yield command. You can yield in one place the first time and another place the next time.\n",
    "\n",
    "The cell below shows a simple function using both forms so that you can see the difference. Notice that you cannot use the result in the same way. A result that is returned is passed directly as value whereas a result that is yielded must be used in an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_count_to_ten():\n",
    "    return list(range(1,11))\n",
    "\n",
    "\n",
    "def yield_count_to_ten():\n",
    "    for i in range(1, 11):\n",
    "        yield i\n",
    "\n",
    "        \n",
    "l = return_count_to_ten()\n",
    "print(l)\n",
    "    \n",
    "i = yield_count_to_ten()\n",
    "print ('yield')\n",
    "print(i)\n",
    "\n",
    "\n",
    "for i in yield_count_to_ten():\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we delimited tokens by looking for spaces between them. You should have noticed that it doesn't work very well because it doesn't account for punctuation symbols. We need a better way to do this and, ideally, a separate function to do it.\n",
    "\n",
    "Because it is hard to follow, here is a summary of the logic of the new function, `split_tokens(input_text)`:\n",
    "\n",
    "The function reads the whole string one character at a time, adding characters to the token variable.\n",
    "- When it encounters a delimiter it yields the token.\n",
    "- If the token is empty it yields the delimiter character - unless it is a space - because the delimiter is an item of punctuation which is itself a token.\n",
    "- After returning a token the variable is reset to an empty string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(input_text):\n",
    "    \"\"\"\n",
    "    Take an input text, split it into tokens, find the\n",
    "    token's shape, make a feature\n",
    "    vector with the token itself and its shape, return\n",
    "    a list of all token feature vectors found in the input.\n",
    "    :param input_text: A character string containing spaces\n",
    "    :return: A list of token feature vectors (token, shape).\n",
    "        Sample output: [('a', 'alpha'), ('7', 'digit'), ('A27', 'alnum')]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Now it's up to the split_tokes function to decide what a token is.\n",
    "    # List comprehension creates a list by extracting elements from\n",
    "    # an iterable object, in this case Python automatically converts the\n",
    "    # split_tokens function into an iterable object because it uses the \"yield\" statement:\n",
    "    \n",
    "    tokens = [token for token in split_tokens(input_text)]\n",
    "    return map(make_token_feature_vector, tokens)\n",
    "\n",
    "\n",
    "def split_tokens(input_text):\n",
    "    \"\"\"\n",
    "    This function decides how to delimit a token. It takes an input\n",
    "    string, iterates over it character by character; it collects\n",
    "    constituent characters in the output token; punctuation characters\n",
    "    are considered delimiters therefore become tokens of their own; the\n",
    "    space character is removed from tokens. Yield each found token at\n",
    "    a time.\n",
    "    :param input_text: A character string containing a mix of text and delimiter characters.\n",
    "    :yield A character string which is either free from delimiters or\n",
    "        is a delimiter itself.\n",
    "    \"\"\"\n",
    "\n",
    "    DELIMITERS = \",:!?.\\n\"\n",
    "    token = \"\"\n",
    "    for char in input_text:\n",
    "        if char in DELIMITERS:  # test if the input character is a delimiter (substring presence)\n",
    "            \n",
    "            # Character strings, lists, etc, have a logical truth value in Python;\n",
    "            # an empty string is False, if it has characters it is True.\n",
    "            \n",
    "            if not token:  # same as token == \"\"\n",
    "                yield char\n",
    "            else:\n",
    "                \n",
    "                # Return token to the calling program, but next time this function\n",
    "                # is called, continue from\n",
    "                # the next statement rather than from the beginning of the function:\n",
    "                \n",
    "                yield token  # After yielding control to the calling program,\n",
    "                             # this function will execute the next statement:\n",
    "                token = \"\"  # Pick up execution from here.\n",
    "                yield char\n",
    "        elif char == \" \":\n",
    "            if token:  # same as token != \"\"\n",
    "                yield token\n",
    "                token = \"\"\n",
    "        else:\n",
    "            token += char\n",
    "\n",
    "for token in make_tokens(sample_text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the function `split_tokens` yields the result instead of returning it. This means that it continues from the same point next time it is called.\n",
    "\n",
    "### Exercise 5\n",
    "In the empty cell below try calling the function `split_tokens` on `sample_text`. What happens?\n",
    "\n",
    "Notice that the programme does not make a simple function call, it uses it in a list comprehension which iterates over it. Another common way to collect the yields would be with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a python program (extension material)\n",
    "We now look at the difference between three different ways of running a python program. \n",
    "\n",
    "The first is the way used in the above examples: simply typing or pasting the code into a notebook (or console) and running it.\n",
    "\n",
    "Very similar to the first way is to import the code from a file or module into a notebook (or console). If you import a module, python will automatically run it. That means it reads and executes every line in the file. If the module contains function definitions, executing them means creating the functions. If it contains code that calls functions, python will make those calls and run the functions.  \n",
    "\n",
    "The third way is to run the module from the command line by typing python followed by the module name including the `.py` suffix.\n",
    "\n",
    "Python behaves the same for the second and third method. However, it is often useful to have a module that runs using the third method but doesn't run using the second i.e. you can import the functions, and perhaps some variables, without running anything. To achieve this, modules often include the line  \n",
    "- `if __name__ == \"__main__\"`  \n",
    "as in the cell below. \n",
    "\n",
    "This will run when called from the command line, but not when the file is imported.\n",
    "\n",
    "The cell below contains the programs for the tokens exercise. It is also stored in a file named \"Exercise.py\" You don't need to read the code as nothing has changed (apart from the addition of one line for testing which was added only to the saved file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(input_text):\n",
    "    \"\"\"\n",
    "    Take an input text, split it into tokens, find the\n",
    "    token's shape, make a feature\n",
    "    vector with the token itself and its shape, return\n",
    "    a list of all token feature vectors found in the input.\n",
    "    :param input_text: A character string containing spaces\n",
    "    :return: A list of token feature vectors (token, shape).\n",
    "        Sample output: [('a', 'alpha'), ('7', 'digit'), ('A27', 'alnum')]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Now it's up to the split_tokes function to decide what a token is.\n",
    "    # List comprehension creates a list by extracting elements from\n",
    "    # an iterable object, in this case Python automatically converts the\n",
    "    # split_tokens function into an iterable object because it uses the \"yield\" statement:\n",
    "    \n",
    "    tokens = [token for token in split_tokens(input_text)]\n",
    "    return map(make_token_feature_vector, tokens)\n",
    "\n",
    "\n",
    "def make_token_feature_vector(token):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a token, extract its shape and return a\n",
    "    vector with the token itself and its shape\n",
    "    :param token: A character string\n",
    "    :return: A tuple (token, shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    if token.isalpha():\n",
    "        return (token, \"alpha\")\n",
    "    elif token.isdigit():\n",
    "        return (token, \"digit\")\n",
    "    elif token.isalnum():\n",
    "        return (token, \"alnum\")\n",
    "    elif token in \",:;\":  \n",
    "        return (token, \"punctuation\")\n",
    "    elif token in \".!?\":  \n",
    "        return (token, \"sentence_end\")\n",
    "    elif token == \"\\n\":  \n",
    "        return (token, \"paragraph_end\")\n",
    "    else:\n",
    "        return (token, \"other\")\n",
    "\n",
    "\n",
    "\n",
    "def split_tokens(input_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function decides how to delimit a token. It takes an input\n",
    "    string, iterates over it character by character; it collects\n",
    "    constituent characters in the output token; punctuation characters\n",
    "    are considered delimiters therefore become tokens of their own; the\n",
    "    space character is removed from tokens. Yield each found token at\n",
    "    a time.\n",
    "    :param input_text: A character string containing a mix of text and delimiter characters.\n",
    "    :yield A character string which is either free from delimiters or\n",
    "        is a delimiter itself.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First decide what characters delimit a token:\n",
    "    DELIMITERS = \",:!?.\\n\"\n",
    "    \n",
    "    token = \"\"\n",
    "    for char in input_text:\n",
    "        \n",
    "        if char in DELIMITERS:  # test if the input character is a delimiter (substring presence)\n",
    "            \n",
    "            # Character strings, lists, etc, have a logical truth value in Python;\n",
    "            # an empty string is False, if it has characters it is True.\n",
    "            \n",
    "            if not token:  # same as token == \"\"\n",
    "                yield char\n",
    "            else:\n",
    "                \n",
    "                # Return token to the calling program, but next time this function\n",
    "                # is called, continue from\n",
    "                # the next statement rather than from the beginning of the function:\n",
    "                \n",
    "                yield token  # After yielding control to the calling program,\n",
    "                             # this function will execute the next statement:\n",
    "                token = \"\"  # Pick up execution from here.\n",
    "                yield char\n",
    "        elif char == \" \":\n",
    "            if token:  # same as token != \"\"\n",
    "                yield token\n",
    "                token = \"\"\n",
    "        else:\n",
    "            token += char\n",
    "            \n",
    "sample_text = \"This is a sample sentence01 showing 7 different token types: alphabetic, numeric, alphanumeric, Title, UPPERCASE, CamelCase and punctuation!\\nSentences like that should not exist. They're too artificial.\\nA REAL sentence looks different. It has flavour to it. You can smell it; it's like Pythonic code, you know?\\nHave you heard of 'code smell'? Google it if you haven't.\"            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for token in make_tokens(sample_text):\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "Try the following.\n",
    "\n",
    "1. Execute the cell above and look at what happens.\n",
    "\n",
    "2. In the empty cell below execute:  \n",
    "`import Exercise`  \n",
    "Note the capital letter in the filename. \n",
    "It should not run the program. \n",
    "\n",
    "To understand what has happened, run each the following commands one at a time:  \n",
    "`print(noone)`  \n",
    "`print(Exercise.noone)`  \n",
    "`from Exercise import noone`  \n",
    "`print(noone)` \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `noone` did not exist in the original program (it was assigned in the test line that was added to the file).\n",
    "- Notice the difference between the two types of import. Using the second type is more convenient as you don't have to specify the namespace to access functions and variables.\n",
    "- For this reason people sometimes use the command  \n",
    "`from module import *`  \n",
    "However, this is dangerous as you can easily overwrite existing names and python will not warn you. Using the import command in this way is considered bad practice. You can sometimes get away with it when importing your own module, but avoid it with library modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
