{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2: Basic Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic (Topic 2) and Topic 3 concern the task of sentiment analysis. You will be using a corpus of **book reviews** within an **Amazon review corpus**.\n",
    "\n",
    "You be exploring various techniques that can be used to classify Amazon book reviews as either positive or negative. \n",
    "\n",
    "You will be developing your own Word List classifiers and then comparing them to the NLTK Naïve Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something for you to do\n",
    "- The first thing you need to do is run the following cell. This will give you access to the Sussex NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Edit this cell to uncomment one line and remove the one that follows\n",
    "\n",
    "import sys\n",
    "#sys.path.append(r'T:\\Departments\\Informatics\\LanguageEngineering') \n",
    "sys.path.append(r'/Users/davidw/Documents/teach/NLE/resources')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the next two lab sessions you will be training and testing various document classifiers. It is important that the data used in the testing phase is not used during the training phase, since this can lead to overestimating performance. This section describes how to use the <code style=\"background-color: #F5F5F5;\">split_data</code> function in order to get separate training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "\n",
    " \n",
    "def split_data(data, ratio=0.7):\n",
    "    data = list(data)\n",
    " \n",
    "    n = len(data)  #Found out number of samples present\n",
    "    train_indices = sample(xrange(n), int(n * ratio))          #Randomly select training indices\n",
    "    test_indices = list(set(xrange(n)) - set(train_indices))   #Randomly select testing indices\n",
    " \n",
    "    training_data = [data[i] for i in train_indices]           #Use training indices to select data\n",
    "    testing_data = [data[i] for i in test_indices]             #Use testing indices to select data\n",
    " \n",
    "    return (training_data, testing_data)                       #Return split data\n",
    " \n",
    "#Create an Amazon corpus reader pointing at only book reviews\n",
    "book_reader = AmazonReviewCorpusReader().category(\"book\")\n",
    "\n",
    "#In order to get even random splits, where each data set is a list of Amazon Review objects.\n",
    "pos_training_data, pos_testing_data = split_data(book_reader.positive().documents()) #See the note below this code snippet \n",
    "neg_training_data, neg_testing_data = split_data(book_reader.negative().documents())\n",
    "\n",
    "#You can also combine the training data\n",
    "training_data = pos_training_data + neg_training_data\n",
    "testing_data = pos_testing_data + neg_testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Using the documents function on the Amazon corpus reader returns a generator over reviews in the corpus (each document in the Amazon corpus is a product review). Each review is an instance of a Python class called `AmazonReview`, which we have defined. An `AmazonReview` object contains all the data about a review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function**: `split_data`\n",
    "\n",
    "- Arguments\n",
    " - An iterable over data (e.g. list, generator)  \n",
    " - Ratio of training to testing data. The default (0.7) returns 70% training and 30% testing\n",
    "- Returns\n",
    " - A split of the original data, into two chunks (stored in a tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do\n",
    "\n",
    "- Use the code snippet above to split the book review corpus in various ways, and by measuring the size of the resulting splits, check that the size of both splits match the specified ratios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating word lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section will explain how to use a sentiment classifier that bases its decisions on word lists. The classifier requires a list of words indicating positive sentiment, and a second list of words indicating negative sentiment. Given positive and negative word lists, a document's overall sentiment is determined based on counts of occurrences of words that occur in the two lists. In this section we are concerned with the creation of the word lists. We will be considering both hand-crafted lists and automatically generated lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do\n",
    "\n",
    "- Create a reasonably long hand-crafted list of words that you think indicate positive sentiment.\n",
    "- Create a reasonably long hand-crafted list of words that indicate negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you should try to derive word lists from the data. One way to do this, is to use the most frequent words in positive reviews as your positive list, and the most frequent words in negative reviews as your negative list. This can be done with the [NLTK <code style=\"background-color: #F5F5F5;\">FreqDist</code>](http://www.nltk.org/api/nltk.html#module-nltk.probability) object. The following code should get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "\n",
    "#Helper function. Given a list of reviews, return a list of all the words in those reviews\n",
    "def get_all_words(amazon_reviews):\n",
    "    return reduce(lambda words,review: words + review.words(), amazon_reviews, [])\n",
    "\n",
    "#A frequency distribution over all words in positive book reviews\n",
    "pos_book_freqdist = FreqDist(get_all_words(pos_training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do\n",
    "\n",
    "- Extend the above code to construct positive and negative word lists consisting of the top k most frequent positive words and the top k most frequent negative words.\n",
    "- Implement an alternative approach that creates positive and negative word lists consisting of all positive words occurring more than k times, and negative words occurring more than k times.\n",
    "- Using the training data, create word lists using both of the above approaches. Do not use the test data for this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a word list based classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a number of word lists for use with a classifier. The following code can be used as the basis for creating a word list based classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.classify.api import ClassifierI\n",
    "import random\n",
    "\n",
    "class SimpleClassifier(ClassifierI): \n",
    "\n",
    "    def __init__(self, pos, neg): \n",
    "        self._pos = pos \n",
    "        self._neg = neg \n",
    "\n",
    "    def classify(self, words): \n",
    "        score = 0\n",
    "        \n",
    "        # add code here that assigns an appropriate value to score\n",
    "        \n",
    "        return \"N\" if score < 0 else \"P\" \n",
    "\n",
    "    def batch_classify(self, docs): \n",
    "        return [self.classify(doc.words() if hasattr(doc, 'words') else doc) for doc in docs] \n",
    "\n",
    "    def labels(self): \n",
    "        return (\"P\", \"N\")\n",
    "\n",
    "#Example usage:\n",
    "\n",
    "book_classifier = SimpleClassifier(positive_book_words_list, negative_book_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do\n",
    "\n",
    "- Complete the `classify` method in the above code as specified below.\n",
    "- Test your classifier on several very simple hand-crafted examples to verify that you have implemented `classify` correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier is initialised with a list of positive words, and a list of negative words. The words of a document are passed to the `classify` method (which is partially completed in the above code fragment). The <code style=\"background-color: #F5F5F5;\">classify</code> method should be defined so that each occurrence of a negative word decrements <code style=\"background-color: #F5F5F5;\">score</code>, and each occurrence of a positive word increments <code style=\"background-color: #F5F5F5;\">score</code>. If the final value of <code style=\"background-color: #F5F5F5;\">score</code> is 0, then the classification decision should be made randomly; for <code style=\"background-color: #F5F5F5;\">score</code> less than 0, an \"<code style=\"background-color: #F5F5F5;\">N</code>\" for \"negative\" is returned, otherwise \"<code style=\"background-color: #F5F5F5;\">P</code>\" for positive is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating word list based classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code that uses an evaluation function in order to determine how well your classifier performs. The function returns the <b>accuracy</b> of a classifier. The accuracy metric is defined as the proportion of documents that were correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sussex_nltk.stats import evaluate_wordlist_classifier\n",
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "\n",
    "#Create a new classifier with your words lists\n",
    "book_classifier = SimpleClassifier(positive_book_words_list, negative_book_words_list)\n",
    "\n",
    "#Evaluate classifier\n",
    "#The function requires three arguments:\n",
    "# 1. Word list based classifer\n",
    "# 2. A list (or generator) of positive AmazonReview objects\n",
    "# 3. A list (or generator) of negative AmazonReview objects\n",
    "accuracy = evaluate_wordlist_classifier(book_classifier, pos_testing_data, neg_testing_data)  \n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do  \n",
    "\n",
    "You have two experiments to perform:\n",
    "- Evaluate the performance of a classifier using hand-crafted lists.\n",
    "- Evaluate the performance of a classifier using lists derived from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training/testing data for Naïve Bayes (NB) classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK Naïve Bayes classifier requires the data to be in a particular format. So the data should be formatted using the <code style=\"background-color: #F5F5F5;\">format_data</code> function below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "For now, ignore the third argument to `format_data`, this will be used in the next lab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "\n",
    "def format_data(reviews, label, feature_extraction_fn=None):\n",
    "    if feature_extraction_fn is None: #If a feature extraction function is not provided, use simply the words of the review as features\n",
    "        data = [(dict([(feature, True) for feature in review.words()]), label) for review in reviews]\n",
    "    else:\n",
    "        data = [(dict([(feature, True) for feature in feature_extraction_fn(review)]), label) for review in reviews]\n",
    "    return data\n",
    "\n",
    "#After you've split the data up as shown earlier, you can use the split data like this:\n",
    "#Format the positive and negative separately\n",
    "formatted_pos_training = format_data(pos_training_data, \"pos\") \n",
    "formatted_neg_training = format_data(neg_training_data, \"neg\") \n",
    "#Combine them\n",
    "formatted_training_data = formatted_pos_training + formatted_neg_training\n",
    "\n",
    "#Same again but for the testing data\n",
    "formatted_pos_testing = format_data(pos_testing_data, \"pos\") \n",
    "formatted_neg_testing = format_data(neg_testing_data, \"neg\") \n",
    "#Combine them\n",
    "formatted_testing_data = formatted_pos_testing + formatted_neg_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do\n",
    "\n",
    "- Look carefully at the above code for `format_data` and make sure that you understand why the implementation satisfies the specification below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function**: `format_data`\n",
    "- Arguments\n",
    " - An iterable (e.g. list, generator) over AmazonReview objects.  \n",
    " - A label to assign the reviews in the corpus reader (\"pos\" or \"neg\" for positive and negative respectively).  \n",
    " - (optional) A function for extracting features from review (no need to use this until the next lab session).\n",
    "- Returns\n",
    " - A list of dictionaries of features extracted from reviews, each mapped to the sentiment of the review. Formatted ready for NB classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and evaluating a Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows how to train and test a NB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "#Train on a list of reviews\n",
    "nb_classifier = NaiveBayesClassifier.train(formatted_training_data)\n",
    "\n",
    "#Test on another list of reviews\n",
    "print \"Accuracy:\", accuracy(nb_classifier, formatted_testing_data)\n",
    "\n",
    "#Print the features that the NB classifier found to be most important in making classifications\n",
    "nb_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something for you to do\n",
    "- Investigate the performance of the various wordlist approaches and the Naïve Bayes (NB) classifier.\n",
    "- Compare the most informative features in Naïve Bayes training with your word lists (use the `show_most_informative_features` method of the NB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
