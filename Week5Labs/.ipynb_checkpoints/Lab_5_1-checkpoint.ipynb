{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Lexical Semantics\n",
    "\n",
    "This week we turn our attention to lexical semantics, i.e., the meaning of words.  In this lab, you will be\n",
    "* exploring the WordNet resource\n",
    "* learning about lexical relations such as synonymy and hyponymy\n",
    "* quantifying semantic similarity via distance in the WordNet hierarchy\n",
    "* comparing WordNet similarity scores with human synonymy judgements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets import WordNet from the nltk library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it may be necessary to run the nltk downloader, depending on what you have previously downloaded\n",
    "#if this cell fails when you run it, then uncomment and run the following lines\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic as wn_ic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating WordNet\n",
    "\n",
    "Central to the organisation of WordNet is the idea of a synset.  Words have senses and senses are grouped with synonymous senses (of other words) in **synsets**\n",
    "\n",
    "If you want to find out which synsets a word belongs to, you use the `synsets` function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets(\"book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of `Synset` objects each of which has a unique identifier containing one of its words, its part of speech and a number.  `Synset('book.n.01')` is the first noun sense of *book*.  However the word book is also in `Synset('record.n.05')` which is the fifth noun sense of *record*.  Lets inspect this synset further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_synsets=wn.synsets('book')\n",
    "recordn5=book_synsets[2]\n",
    "print(recordn5.lemma_names())  #get the words in the synset\n",
    "print(recordn5.definition())   #get the definition of the synset\n",
    "print(recordn5.examples())  #get examples of the words used in this sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to find synsets associated with a particular part of speech of a word then you can give `synsets` an extra argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_of_speech={\"noun\":wn.NOUN,\"verb\":wn.VERB,\"adjective\":wn.ADJ,\"adverb\":wn.ADV}\n",
    "\n",
    "key=\"adjective\"\n",
    "print(wn.synsets(\"red\",parts_of_speech[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "* Write code to compute the number of synsets of each part of speech (noun, verb, adjective and adverb) for each of the following words:- book, chicken, counter, twig, fast, plant\n",
    "* Store and display the information using a Pandas dataframe\n",
    "\n",
    "Hint: you could use a nested list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Synset` object also has `hyponyms` and `hypernyms` methods which return hyponym and hypernym synsets respectively.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordn5.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordn5.hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the hyponymy relation forms a tree, we would expect synsets to generally have multiple hyponyms and a single hypernym.  At the top of the tree (also called the **root**), the hypernym list will be empty.  Most noun concepts in WordNet share a common root hypernym which is *entity*.  At the bottom of the tree (also referred to as the **leaves** of the tree), the hyponym list will be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "Write a function, `distance_to_root` that will take a Synset and traverse up the tree until it reaches a root of the tree.  When it does so, it should return the number of steps taken.\n",
    "\n",
    "Hint: This can be done using **recursion**, where a function repeatedly calls itself.  You need to define:\n",
    "* a base case:  How will the function know when it is at the top of the tree and what should it return?\n",
    "* a recursive step: In the general case, the function should call itself with a simpler problem (a Synset which is closer to the top of the tree).  When it gets the result of this function call, it needs to modify it in some way and then return its own answer\n",
    "\n",
    "Make sure you test your function.  You should find that the 5th noun sense of record is 6 steps from the top.\n",
    "\n",
    "How far are all of the other noun sense of book from a root of the tree?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Similarity in WordNet\n",
    "\n",
    "The simplest way of defining how similar two concepts are according to WordNet is to use the pathlength measure:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\mbox{sim}(\\mbox{synsetA},\\mbox{synsetB})=\\frac{1}{1+\\mbox{lengthOfPath}(\\mbox{synsetA},\\mbox{synsetB})}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We have also introduced other measures in the lectures which incorporate **information content**, i.e., the amount of information we receive when a word from a given synset is used (there is more information in being told that something is a *poodle* than in being told it is an *animal*).\n",
    "\n",
    "The `nltk.wn` module has built-in functions for computing these similarities between synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books=wn.synsets(\"book\",wn.NOUN)\n",
    "print(\"path_similarity {}\".format(wn.path_similarity(books[0],books[1])))\n",
    "\n",
    "brown_ic=wn_ic.ic(\"ic-brown.dat\")  #this gets information content data from the Brown corpus\n",
    "print(\"resnik_similarity {}\".format(wn.res_similarity(books[0],books[1],brown_ic)))\n",
    "print(\"lin_similarity {}\".format(wn.lin_similarity(books[0],books[1],brown_ic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note it is impossible to compare synsets of different parts of speech using these methods because they are not connected via hyponymy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksN=wn.synsets(\"book\",wn.NOUN)\n",
    "booksV=wn.synsets(\"book\",wn.VERB)\n",
    "print(\"path_similarity {}\".format(wn.path_similarity(booksN[0],booksV[1])))\n",
    "print(\"resnik_similarity {}\".format(wn.res_similarity(booksN[0],booksV[1],brown_ic)))\n",
    "print(\"lin_similarity {}\".format(wn.lin_similarity(booksN[0],booksV[1],brown_ic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "The similarity of two **words** with a given part of speech is defined as the **maximum** similarity of all possible sense pairings.  If word A has 5 noun senses and word B has 4 noun senses than there are 20 possible sense pairings to check.\n",
    "\n",
    "* Write a function which will compute the path_similarity of two nouns.\n",
    "* Make sure you test it.  The correct answer for *chicken* and *car* is 0.0909 to 3SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "Generalise your path_similarity function so that it takes an extra optional argument:\n",
    "* the similarity measure to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing WordNet Similarities with Human Synonymy Judgements\n",
    "\n",
    "The file `mcdata.csv` contains human synonymy judgements for a list of 30 noun pairs.   We can read in a `.csv` file using the `csv` library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "filename='mcdata.csv'\n",
    "\n",
    "with open(filename,'r') as filestream:\n",
    "    mcdata=list(csv.reader(filestream,delimiter=','))\n",
    "\n",
    "df=pd.DataFrame(mcdata,columns=[\"word1\",\"word2\",\"human similarity\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the human similarity judgements range between 0 and 5.\n",
    "\n",
    "### Exercise 3.1\n",
    "Write code that will \n",
    "* compute the WordNet path_similarity for every pair of words in this data; and\n",
    "* add it as a column in the dataframe.  If you have the path similarity scores in a list called `scores`, you can do this using `df['path']=scores`\n",
    "\n",
    "Repeat for the Resnik and Lin similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pandas functionality to produce scatter plots and examine the correlation between different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"human similarity\"\n",
    "y=\"path\"\n",
    "def draw_scatter(df,x,y):\n",
    "\n",
    "    df[x]=df[x].map(float)\n",
    "    df[y]=df[y].map(float)\n",
    "    \n",
    "    df.plot.scatter(x,y)\n",
    "draw_scatter(df,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2\n",
    "Generate scatter plots showing Resnik similarity against human similarity and Lin similarity against human similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame.corr()` method will compute the correlation for all pairs of columns with numeric values.  It is better to use Spearman's rank correlation coefficient than Pearson's product-moment correlation coefficient, since similarity scores are unlikely to be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "* Looking at the scatter plots and the correlation coefficients, what do you conclude about the different WordNet similarity measures?\n",
    "* Do you have any reservations about your conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
